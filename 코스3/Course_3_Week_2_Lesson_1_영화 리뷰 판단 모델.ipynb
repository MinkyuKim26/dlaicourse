{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Course 3 - Week 2 - Lesson 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "source": [
        "# 영화 리뷰 긍정, 부정 판단 모델\n",
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%202%20-%20Lesson%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-AhVYeBWgQ3"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "!pip install -q tensorflow-datasets"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IoM4VFxWpMR",
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "imdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True) # TFDS(텐서플로우 데이터셋. 텐서플로우에서 제공하는 데이터다.)에서 imdb 데이터셋 불러오기. imdb에는 리뷰 내용과 리뷰의 긍정, 부정에 대한 판단이 들어가고 info는...뭐지? \n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":05<00:02, 4394.95 examples/s]\u001b[A\n",
            "Generating train examples...:  67%|██████▋   | 16629/25000 [00:05<00:01, 4504.08 examples/s]\u001b[A\n",
            "Generating train examples...:  68%|██████▊   | 17115/25000 [00:05<00:01, 4602.51 examples/s]\u001b[A\n",
            "Generating train examples...:  70%|███████   | 17595/25000 [00:05<00:01, 4659.24 examples/s]\u001b[A\n",
            "Generating train examples...:  72%|███████▏  | 18068/25000 [00:06<00:01, 4415.68 examples/s]\u001b[A\n",
            "Generating train examples...:  74%|███████▍  | 18517/25000 [00:06<00:01, 4290.81 examples/s]\u001b[A\n",
            "Generating train examples...:  76%|███████▌  | 18952/25000 [00:06<00:01, 4180.26 examples/s]\u001b[A\n",
            "Generating train examples...:  78%|███████▊  | 19375/25000 [00:06<00:01, 4093.17 examples/s]\u001b[A\n",
            "Generating train examples...:  79%|███████▉  | 19789/25000 [00:06<00:01, 4024.46 examples/s]\u001b[A\n",
            "Generating train examples...:  81%|████████  | 20195/25000 [00:06<00:01, 3902.64 examples/s]\u001b[A\n",
            "Generating train examples...:  82%|████████▏ | 20589/25000 [00:06<00:01, 3862.64 examples/s]\u001b[A\n",
            "Generating train examples...:  84%|████████▍ | 21016/25000 [00:06<00:01, 3975.03 examples/s]\u001b[A\n",
            "Generating train examples...:  86%|████████▌ | 21498/25000 [00:06<00:00, 4194.61 examples/s]\u001b[A\n",
            "Generating train examples...:  88%|████████▊ | 21973/25000 [00:06<00:00, 4345.13 examples/s]\u001b[A\n",
            "Generating train examples...:  90%|████████▉ | 22454/25000 [00:07<00:00, 4474.66 examples/s]\u001b[A\n",
            "Generating train examples...:  92%|█████████▏| 22934/25000 [00:07<00:00, 4566.34 examples/s]\u001b[A\n",
            "Generating train examples...:  94%|█████████▎| 23412/25000 [00:07<00:00, 4627.42 examples/s]\u001b[A\n",
            "Generating train examples...:  96%|█████████▌| 23890/25000 [00:07<00:00, 4671.38 examples/s]\u001b[A\n",
            "Generating train examples...:  97%|█████████▋| 24360/25000 [00:07<00:00, 4496.20 examples/s]\u001b[A\n",
            "Generating train examples...:  99%|█████████▉| 24813/25000 [00:07<00:00, 4400.06 examples/s]\u001b[A\n",
            "                                                                                            \u001b[A\n",
            "Shuffling imdb_reviews-train.tfrecord...:   0%|          | 0/25000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling imdb_reviews-train.tfrecord...:  51%|█████     | 12713/25000 [00:00<00:00, 127126.18 examples/s]\u001b[A\n",
            "Shuffling imdb_reviews-train.tfrecord...:  96%|█████████▋| 24068/25000 [00:00<00:00, 122721.45 examples/s]\u001b[A\n",
            "Generating splits...:  33%|███▎      | 1/3 [00:10<00:21, 10.86s/ splits]\n",
            "Generating test examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]\u001b[A\n",
            "Generating test examples...:   0%|          | 1/25000 [00:00<3:13:03,  2.16 examples/s]\u001b[A\n",
            "Generating test examples...:   2%|▏         | 384/25000 [00:00<2:13:06,  3.08 examples/s]\u001b[A\n",
            "Generating test examples...:   3%|▎         | 816/25000 [00:00<1:31:33,  4.40 examples/s]\u001b[A\n",
            "Generating test examples...:   5%|▌         | 1262/25000 [00:00<1:02:56,  6.29 examples/s]\u001b[A\n",
            "Generating test examples...:   7%|▋         | 1746/25000 [00:00<43:11,  8.97 examples/s]  \u001b[A\n",
            "Generating test examples...:   9%|▉         | 2228/25000 [00:00<29:37, 12.81 examples/s]\u001b[A\n",
            "Generating test examples...:  11%|█         | 2672/25000 [00:01<20:21, 18.28 examples/s]\u001b[A\n",
            "Generating test examples...:  13%|█▎        | 3148/25000 [00:01<13:58, 26.07 examples/s]\u001b[A\n",
            "Generating test examples...:  14%|█▍        | 3587/25000 [00:01<09:36, 37.15 examples/s]\u001b[A\n",
            "Generating test examples...:  16%|█▌        | 4025/25000 [00:01<06:36, 52.88 examples/s]\u001b[A\n",
            "Generating test examples...:  18%|█▊        | 4486/25000 [00:01<04:32, 75.17 examples/s]\u001b[A\n",
            "Generating test examples...:  20%|█▉        | 4930/25000 [00:01<03:08, 106.61 examples/s]\u001b[A\n",
            "Generating test examples...:  22%|██▏       | 5400/25000 [00:01<02:09, 150.83 examples/s]\u001b[A\n",
            "Generating test examples...:  23%|██▎       | 5850/25000 [00:01<01:30, 212.33 examples/s]\u001b[A\n",
            "Generating test examples...:  25%|██▌       | 6296/25000 [00:01<01:02, 297.08 examples/s]\u001b[A\n",
            "Generating test examples...:  27%|██▋       | 6749/25000 [00:01<00:44, 412.77 examples/s]\u001b[A\n",
            "Generating test examples...:  29%|██▉       | 7218/25000 [00:02<00:31, 568.24 examples/s]\u001b[A\n",
            "Generating test examples...:  31%|███       | 7695/25000 [00:02<00:22, 772.33 examples/s]\u001b[A\n",
            "Generating test examples...:  33%|███▎      | 8189/25000 [00:02<00:16, 1033.93 examples/s]\u001b[A\n",
            "Generating test examples...:  35%|███▍      | 8659/25000 [00:02<00:12, 1342.45 examples/s]\u001b[A\n",
            "Generating test examples...:  37%|███▋      | 9137/25000 [00:02<00:09, 1711.44 examples/s]\u001b[A\n",
            "Generating test examples...:  38%|███▊      | 9619/25000 [00:02<00:07, 2121.58 examples/s]\u001b[A\n",
            "Generating test examples...:  40%|████      | 10100/25000 [00:02<00:05, 2548.60 examples/s]\u001b[A\n",
            "Generating test examples...:  42%|████▏     | 10588/25000 [00:02<00:04, 2974.39 examples/s]\u001b[A\n",
            "Generating test examples...:  44%|████▍     | 11078/25000 [00:02<00:04, 3371.35 examples/s]\u001b[A\n",
            "Generating test examples...:  46%|████▋     | 11572/25000 [00:02<00:03, 3725.02 examples/s]\u001b[A\n",
            "Generating test examples...:  48%|████▊     | 12062/25000 [00:03<00:03, 4013.12 examples/s]\u001b[A\n",
            "Generating test examples...:  50%|█████     | 12551/25000 [00:03<00:02, 4240.81 examples/s]\u001b[A\n",
            "Generating test examples...:  52%|█████▏    | 13039/25000 [00:03<00:02, 4409.61 examples/s]\u001b[A\n",
            "Generating test examples...:  54%|█████▍    | 13526/25000 [00:03<00:02, 4537.94 examples/s]\u001b[A\n",
            "Generating test examples...:  56%|█████▌    | 14014/25000 [00:03<00:02, 4633.62 examples/s]\u001b[A\n",
            "Generating test examples...:  58%|█████▊    | 14501/25000 [00:03<00:02, 4632.86 examples/s]\u001b[A\n",
            "Generating test examples...:  60%|█████▉    | 14989/25000 [00:03<00:02, 4703.52 examples/s]\u001b[A\n",
            "Generating test examples...:  62%|██████▏   | 15476/25000 [00:03<00:02, 4752.21 examples/s]\u001b[A\n",
            "Generating test examples...:  64%|██████▍   | 15962/25000 [00:03<00:01, 4782.42 examples/s]\u001b[A\n",
            "Generating test examples...:  66%|██████▌   | 16447/25000 [00:03<00:01, 4781.48 examples/s]\u001b[A\n",
            "Generating test examples...:  68%|██████▊   | 16930/25000 [00:04<00:01, 4754.47 examples/s]\u001b[A\n",
            "Generating test examples...:  70%|██████▉   | 17426/25000 [00:04<00:01, 4812.45 examples/s]\u001b[A\n",
            "Generating test examples...:  72%|███████▏  | 17910/25000 [00:04<00:01, 4741.67 examples/s]\u001b[A\n",
            "Generating test examples...:  74%|███████▎  | 18393/25000 [00:04<00:01, 4766.49 examples/s]\u001b[A\n",
            "Generating test examples...:  76%|███████▌  | 18878/25000 [00:04<00:01, 4790.51 examples/s]\u001b[A\n",
            "Generating test examples...:  77%|███████▋  | 19358/25000 [00:04<00:01, 4773.33 examples/s]\u001b[A\n",
            "Generating test examples...:  79%|███████▉  | 19847/25000 [00:04<00:01, 4807.38 examples/s]\u001b[A\n",
            "Generating test examples...:  81%|████████▏ | 20329/25000 [00:04<00:00, 4775.00 examples/s]\u001b[A\n",
            "Generating test examples...:  83%|████████▎ | 20815/25000 [00:04<00:00, 4798.72 examples/s]\u001b[A\n",
            "Generating test examples...:  85%|████████▌ | 21297/25000 [00:04<00:00, 4802.77 examples/s]\u001b[A\n",
            "Generating test examples...:  87%|████████▋ | 21780/25000 [00:05<00:00, 4810.81 examples/s]\u001b[A\n",
            "Generating test examples...:  89%|████████▉ | 22263/25000 [00:05<00:00, 4814.17 examples/s]\u001b[A\n",
            "Generating test examples...:  91%|█████████ | 22750/25000 [00:05<00:00, 4829.43 examples/s]\u001b[A\n",
            "Generating test examples...:  93%|█████████▎| 23241/25000 [00:05<00:00, 4851.60 examples/s]\u001b[A\n",
            "Generating test examples...:  95%|█████████▍| 23727/25000 [00:05<00:00, 4803.24 examples/s]\u001b[A\n",
            "Generating test examples...:  97%|█████████▋| 24208/25000 [00:05<00:00, 4798.28 examples/s]\u001b[A\n",
            "Generating test examples...:  99%|█████████▉| 24703/25000 [00:05<00:00, 4841.87 examples/s]\u001b[A\n",
            "                                                                                           \u001b[A\n",
            "Shuffling imdb_reviews-test.tfrecord...:   0%|          | 0/25000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling imdb_reviews-test.tfrecord...:  51%|█████     | 12801/25000 [00:00<00:00, 127993.34 examples/s]\u001b[A\n",
            "Shuffling imdb_reviews-test.tfrecord...:  97%|█████████▋| 24347/25000 [00:00<00:00, 123952.20 examples/s]\u001b[A\n",
            "Generating splits...:  67%|██████▋   | 2/3 [00:21<00:10, 10.69s/ splits]\n",
            "Generating unsupervised examples...:   0%|          | 0/50000 [00:00<?, ? examples/s]\u001b[A\n",
            "Generating unsupervised examples...:   0%|          | 1/50000 [00:03<45:40:28,  3.29s/ examples]\u001b[A\n",
            "Generating unsupervised examples...:   1%|          | 324/50000 [00:03<31:46:01,  2.30s/ examples]\u001b[A\n",
            "Generating unsupervised examples...:   1%|▏         | 698/50000 [00:03<22:04:13,  1.61s/ examples]\u001b[A\n",
            "Generating unsupervised examples...:   2%|▏         | 1095/50000 [00:03<15:19:33,  1.13s/ examples]\u001b[A\n",
            "Generating unsupervised examples...:   3%|▎         | 1507/50000 [00:03<10:38:19,  1.27 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:   4%|▍         | 1910/50000 [00:03<7:23:10,  1.81 examples/s] \u001b[A\n",
            "Generating unsupervised examples...:   5%|▍         | 2336/50000 [00:03<5:07:31,  2.58 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:   6%|▌         | 2775/50000 [00:03<3:33:20,  3.69 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:   6%|▋         | 3243/50000 [00:04<2:27:54,  5.27 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:   7%|▋         | 3694/50000 [00:04<1:42:35,  7.52 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:   8%|▊         | 4126/50000 [00:04<1:11:11, 10.74 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:   9%|▉         | 4601/50000 [00:04<49:22, 15.33 examples/s]  \u001b[A\n",
            "Generating unsupervised examples...:  10%|█         | 5064/50000 [00:04<34:15, 21.86 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  11%|█         | 5555/50000 [00:04<23:45, 31.17 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  12%|█▏        | 6040/50000 [00:04<16:29, 44.41 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  13%|█▎        | 6517/50000 [00:04<11:28, 63.19 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  14%|█▍        | 6987/50000 [00:04<07:59, 89.68 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  15%|█▍        | 7439/50000 [00:05<05:35, 126.99 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  16%|█▌        | 7886/50000 [00:05<03:55, 179.03 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  17%|█▋        | 8321/50000 [00:05<02:46, 250.66 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  17%|█▋        | 8739/50000 [00:05<01:58, 348.59 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  18%|█▊        | 9150/50000 [00:05<01:25, 479.78 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  19%|█▉        | 9566/50000 [00:05<01:01, 653.03 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  20%|██        | 10020/50000 [00:05<00:45, 878.72 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  21%|██        | 10450/50000 [00:05<00:34, 1154.11 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  22%|██▏       | 10875/50000 [00:05<00:26, 1462.11 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  23%|██▎       | 11289/50000 [00:05<00:21, 1809.28 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  23%|██▎       | 11721/50000 [00:06<00:17, 2191.19 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  24%|██▍       | 12159/50000 [00:06<00:14, 2576.78 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  25%|██▌       | 12631/50000 [00:06<00:12, 2982.25 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  26%|██▌       | 13112/50000 [00:06<00:10, 3365.43 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  27%|██▋       | 13590/50000 [00:06<00:09, 3692.25 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  28%|██▊       | 14049/50000 [00:06<00:09, 3860.19 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  29%|██▉       | 14513/50000 [00:06<00:08, 4063.79 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  30%|██▉       | 14984/50000 [00:06<00:08, 4236.06 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  31%|███       | 15462/50000 [00:06<00:07, 4385.06 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  32%|███▏      | 15929/50000 [00:06<00:07, 4463.43 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  33%|███▎      | 16414/50000 [00:07<00:07, 4570.85 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  34%|███▍      | 16885/50000 [00:07<00:07, 4449.41 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  35%|███▍      | 17341/50000 [00:07<00:07, 4466.65 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  36%|███▌      | 17795/50000 [00:07<00:07, 4455.67 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  36%|███▋      | 18246/50000 [00:07<00:07, 4377.84 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  37%|███▋      | 18723/50000 [00:07<00:06, 4488.35 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  38%|███▊      | 19176/50000 [00:07<00:09, 3336.48 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  39%|███▉      | 19597/50000 [00:07<00:08, 3557.42 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  40%|███▉      | 19989/50000 [00:08<00:08, 3596.09 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  41%|████      | 20377/50000 [00:08<00:08, 3675.22 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  42%|████▏     | 20792/50000 [00:08<00:07, 3804.78 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  42%|████▏     | 21207/50000 [00:08<00:07, 3898.60 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  43%|████▎     | 21652/50000 [00:08<00:07, 4046.99 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  44%|████▍     | 22066/50000 [00:08<00:06, 4051.97 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  45%|████▌     | 22508/50000 [00:08<00:06, 4154.76 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  46%|████▌     | 22998/50000 [00:08<00:06, 4351.88 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  47%|████▋     | 23481/50000 [00:08<00:05, 4483.99 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  48%|████▊     | 23971/50000 [00:08<00:05, 4600.75 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  49%|████▉     | 24436/50000 [00:09<00:05, 4596.75 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  50%|████▉     | 24917/50000 [00:09<00:05, 4658.28 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  51%|█████     | 25405/50000 [00:09<00:05, 4721.69 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  52%|█████▏    | 25880/50000 [00:09<00:05, 4666.25 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  53%|█████▎    | 26373/50000 [00:09<00:04, 4739.68 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  54%|█████▎    | 26849/50000 [00:09<00:04, 4730.92 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  55%|█████▍    | 27337/50000 [00:09<00:04, 4773.08 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  56%|█████▌    | 27827/50000 [00:09<00:04, 4809.92 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  57%|█████▋    | 28313/50000 [00:09<00:04, 4823.80 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  58%|█████▊    | 28806/50000 [00:09<00:04, 4853.20 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  59%|█████▊    | 29293/50000 [00:10<00:04, 4857.60 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  60%|█████▉    | 29786/50000 [00:10<00:04, 4877.21 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  61%|██████    | 30280/50000 [00:10<00:04, 4893.70 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  62%|██████▏   | 30770/50000 [00:10<00:03, 4813.59 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  63%|██████▎   | 31256/50000 [00:10<00:03, 4825.26 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  63%|██████▎   | 31749/50000 [00:10<00:03, 4854.89 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  64%|██████▍   | 32239/50000 [00:10<00:03, 4866.76 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  65%|██████▌   | 32730/50000 [00:10<00:03, 4879.13 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  66%|██████▋   | 33219/50000 [00:10<00:03, 4870.04 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  67%|██████▋   | 33707/50000 [00:10<00:03, 4855.06 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  68%|██████▊   | 34193/50000 [00:11<00:03, 4817.89 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  69%|██████▉   | 34679/50000 [00:11<00:03, 4828.52 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  70%|███████   | 35162/50000 [00:11<00:03, 4804.05 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  71%|███████▏  | 35643/50000 [00:11<00:03, 4747.08 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  72%|███████▏  | 36133/50000 [00:11<00:02, 4791.69 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  73%|███████▎  | 36615/50000 [00:11<00:02, 4798.94 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  74%|███████▍  | 37106/50000 [00:11<00:02, 4831.44 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  75%|███████▌  | 37600/50000 [00:11<00:02, 4862.00 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  76%|███████▌  | 38087/50000 [00:11<00:02, 4860.52 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  77%|███████▋  | 38574/50000 [00:11<00:02, 4826.62 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  78%|███████▊  | 39057/50000 [00:12<00:02, 4738.47 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  79%|███████▉  | 39532/50000 [00:12<00:02, 4693.29 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  80%|████████  | 40012/50000 [00:12<00:02, 4721.66 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  81%|████████  | 40495/50000 [00:12<00:01, 4753.17 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  82%|████████▏ | 40971/50000 [00:12<00:01, 4733.49 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  83%|████████▎ | 41445/50000 [00:12<00:01, 4626.32 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  84%|████████▍ | 41909/50000 [00:12<00:01, 4437.31 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  85%|████████▍ | 42355/50000 [00:12<00:01, 4441.16 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  86%|████████▌ | 42835/50000 [00:12<00:01, 4542.00 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  87%|████████▋ | 43291/50000 [00:12<00:01, 4470.12 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  88%|████████▊ | 43773/50000 [00:13<00:01, 4568.33 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  89%|████████▊ | 44254/50000 [00:13<00:01, 4636.73 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  89%|████████▉ | 44719/50000 [00:13<00:01, 4568.32 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  90%|█████████ | 45177/50000 [00:13<00:01, 4347.05 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  91%|█████████ | 45615/50000 [00:13<00:01, 4275.37 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  92%|█████████▏| 46045/50000 [00:13<00:00, 4186.24 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  93%|█████████▎| 46466/50000 [00:13<00:00, 4043.37 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  94%|█████████▍| 46880/50000 [00:13<00:00, 4071.09 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  95%|█████████▍| 47362/50000 [00:13<00:00, 4269.47 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  96%|█████████▌| 47833/50000 [00:14<00:00, 4390.86 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  97%|█████████▋| 48313/50000 [00:14<00:00, 4504.86 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  98%|█████████▊| 48796/50000 [00:14<00:00, 4596.11 examples/s]\u001b[A\n",
            "Generating unsupervised examples...:  99%|█████████▊| 49282/50000 [00:14<00:00, 4671.82 examples/s]\u001b[A\n",
            "Generating unsupervised examples...: 100%|█████████▉| 49768/50000 [00:14<00:00, 4724.52 examples/s]\u001b[A\n",
            "                                                                                                   \u001b[A\n",
            "Shuffling imdb_reviews-unsupervised.tfrecord...:   0%|          | 0/50000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling imdb_reviews-unsupervised.tfrecord...:  19%|█▉        | 9451/50000 [00:00<00:00, 94500.18 examples/s]\u001b[A\n",
            "Shuffling imdb_reviews-unsupervised.tfrecord...:  49%|████▉     | 24596/50000 [00:00<00:00, 106516.04 examples/s]\u001b[A\n",
            "Shuffling imdb_reviews-unsupervised.tfrecord...:  77%|███████▋  | 38618/50000 [00:00<00:00, 114793.71 examples/s]\u001b[A\n",
            "Shuffling imdb_reviews-unsupervised.tfrecord...:  95%|█████████▍| 47395/50000 [00:00<00:00, 104386.69 examples/s]\u001b[A\n",
            "\u001b[1mDataset imdb_reviews downloaded and prepared to /Users/minguinho/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHQ2Ko0zl7M4"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "train_data, test_data = imdb['train'], imdb['test'] # imdb에서 훈련셋과 테스트셋을 불러온다. 따로 저장되어있는듯 \n",
        "\n",
        "# 훈련셋의 문장(입력값), 라벨(긍정인가 부정인가? 출력값) 담는 리스트 \n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "\n",
        "# 테스트셋의 문장, 라벨 담는 리스트\n",
        "testing_sentences = []\n",
        "testing_labels = []\n",
        "\n",
        "# 훈련셋에서 s(sentences), l(label)을 뽑아낸 뒤 training_sentences, training_labels에 담는다. \n",
        "for s,l in train_data:\n",
        "  training_sentences.append(s.numpy().decode('utf8')) # 문자열을 리스트에 담아주는거기 때문에 utf8이나 유니코드 등의 인코딩 방식을 선택해야한다. \n",
        "  training_labels.append(l.numpy())\n",
        "  \n",
        "# 테스트셋\n",
        "for s,l in test_data:\n",
        "  testing_sentences.append(s.numpy().decode('utf8'))\n",
        "  testing_labels.append(l.numpy())\n",
        "\n",
        "# 넘파이 배열로 바꿔준다. 왜냐하면 나중에 훈련시킬 때 넘파이 배열을 받기 때문이다. \n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n15yyMdmoH1"
      },
      "source": [
        "vocab_size = 10000 # 단어 크기\n",
        "embedding_dim = 16 # 임패딩 단위\n",
        "max_length = 120 # 리뷰에 들어있는 최대 단어 갯수. 아무리 길어도 단어 120개가 한계다...라는 것을 나타냄.\n",
        "trunc_type='post' # truncation type. 단어 갯수가 120개보다 많을 때 앞에서부터 자를건지 뒤에서부터 자를건지 결정함 post는 문자열이 120개보다 많으면 뒤에서 자르겠다는 뜻.\n",
        "oov_tok = \"<OOV>\" # 토큰 딕셔너리에 없는 단어는 OOV로 표시\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok) # num_words = vocab_size : 가장 많이 쓰이는 단어 'vocab_size'개만 토큰화 하는거. 그러니까 토큰화 대상인 문자여렝 단어가 20000개 있으면 많이 쓰이는 순으로 나열한 뒤 앞에 있는 10000개의 단어만 토큰화 하고 나머지 10000개는 토큰화하지 않는다. 얘들은 뭐 OOV로 나오겠지\n",
        "tokenizer.fit_on_texts(training_sentences) # 토큰화\n",
        "word_index = tokenizer.word_index # 토큰화 결과 가져오기\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences) # 문장들을 토큰 순서로 나열하기\n",
        "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type) # 패딩. \n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences) # 훈련셋으로 만든 토크나이저로 테스트셋의 시퀀스 출력. 토큰화 하지않은 단어가 많기 때문에 기존에 만들어놨던 걸로 한다. 만약 토크나이저를 새로 만든다면 두 토크나이저는 다른 토크나이저가 되기 때문에 원하는 결과를 얻을 수 없다. \n",
        "testing_padded = pad_sequences(testing_sequences,maxlen=max_length) # 패딩\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9axf0uIXVMhO"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) # 딕셔너리가 원래 [단어 : 토큰]이었는데 이걸 [토큰 : 단어]로 바꾼다. 왜냐하면 이렇게 해야 딕셔너리[i]로 단어를 불러와 시퀀스를 문장으로 만들 수 있거든. \n",
        "# 효율적인 작업을 위한 준비라고 보면 되겠다. \n",
        "\n",
        "# 시퀀스 -> 문장\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text]) # join : 문자열 합치기. get(i, '?')는 i에 해당하는 value(여기서는 단어)가 없으면 ?를 출력하겠다는 의미다. \n",
        "\n",
        "print(decode_review(padded[1]))\n",
        "print(training_sentences[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "? ? ? ? ? ? ? ? i have been known to fall asleep during films but this is usually due to a combination of things including really tired being warm and comfortable on the <OOV> and having just eaten a lot however on this occasion i fell asleep because the film was rubbish the plot development was constant constantly slow and boring things seemed to happen but with no explanation of what was causing them or why i admit i may have missed part of the film but i watched the majority of it and everything just seemed to happen of its own <OOV> without any real concern for anything else i cant recommend this film at all\nI have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NEpdhb8AxID"
      },
      "source": [
        "# 모델 생성\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length), # 임베딩 레이어. 단어의 의미를 단어의 벡터 방향으로 추측하게 하는 것. 각 단어마다 16개의 차원(측정 요소가 16개)을 가진다. \n",
        "    # 두 단어가 가리키는 방향이 비슷하면 두 단어의 의미가 비슷한거다. \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid') # 이진 분류니까 얘 사용\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy']) # 컴파일. 긍정, 부정밖에 없으니 이진 분류를 하니까 binary_crossentropy를 손실 함수로 사용한다. \n",
        "model.summary()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 120, 16)           160000    \n_________________________________________________________________\nflatten (Flatten)            (None, 1920)              0         \n_________________________________________________________________\ndense (Dense)                (None, 6)                 11526     \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 7         \n=================================================================\nTotal params: 171,533\nTrainable params: 171,533\nNon-trainable params: 0\n_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5LLrXC-uNX6"
      },
      "source": [
        "num_epochs = 10\n",
        "model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final)) # 훈련"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 3s 2ms/step - loss: 0.6092 - accuracy: 0.6273 - val_loss: 0.3428 - val_accuracy: 0.8490\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.2331 - accuracy: 0.9123 - val_loss: 0.3664 - val_accuracy: 0.8414\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.0773 - accuracy: 0.9852 - val_loss: 0.4537 - val_accuracy: 0.8254\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.0190 - accuracy: 0.9980 - val_loss: 0.5310 - val_accuracy: 0.8260\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.5873 - val_accuracy: 0.8276\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.8270\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 8.0511e-04 - accuracy: 1.0000 - val_loss: 0.6700 - val_accuracy: 0.8294\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.4847e-04 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8294\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 4.0204e-04 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.8284\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 1.7003e-04 - accuracy: 1.0000 - val_loss: 0.7877 - val_accuracy: 0.8298\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9f6332ee20>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAmjJqEyCOF_"
      },
      "source": [
        "# 데이터 그래픽화\n",
        "e = model.layers[0] # 임베딩 레이어(tf.keras.layers.Embedding)의 출력값. 인덱스가 0인데 임베딩 레이어가 나오는 이유는 모델 만들 때 얘를 제일 먼저 넣었기 때문. \n",
        "weights = e.get_weights()[0] # 임베딩 레이어의 가중치\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim) 단어가 10000개고 임베딩 차원이 16차원임"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmB0Uxk0ycP6"
      },
      "source": [
        "# 파일 제작\n",
        "import io\n",
        "\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8') # 16차원 벡터값 저장\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8') # 벡터에 해당하는 단어 저장\n",
        "for word_num in range(1, vocab_size): \n",
        "  word = reverse_word_index[word_num] # 앞서 플립을 통해 [단어 : 토큰] -> [토큰 : 단어]로 만들었다. 그래서 토큰(숫자)가 인덱스 넘버인 배열처럼 사용할 수 있다\n",
        "  embeddings = weights[word_num] # 임베딩 가중치\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDeqpOCVydtq"
      },
      "source": [
        "# 제작한 tsv파일 다운로드. 얘들을 임베딩 프로젝터에서 load하면 임베딩 그래프를 볼 수 있다. 단어를 검색하면 그 단어의 위치가 나오고 비슷한 방향을 지닌 단어들이 주변에 나타난다. \n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRxoxc2apscY"
      },
      "source": [
        "sentence = \"I really think this is amazing. honest.\"\n",
        "sequence = tokenizer.texts_to_sequences([sentence])\n",
        "print(sequence)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11, 64, 102, 12, 7, 478, 1200]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}